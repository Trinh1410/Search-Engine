{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01da9278-4292-4414-8639-4120171bbbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/06 02:08:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WriteToHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Tạo một DataFrame mẫu\n",
    "data = [(\"James\", \"Smith\", \"USA\", \"CA\"),\n",
    "        (\"Michael\", \"Rose\", \"USA\", \"NY\"),\n",
    "        (\"Robert\", \"Williams\", \"USA\", \"CA\"),\n",
    "        (\"Maria\", \"Jones\", \"USA\", \"FL\")]\n",
    "\n",
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Ghi DataFrame vào HDFS với tiêu đề\n",
    "df.write.csv(\"hdfs://namenode:9000/user/nhatrinh/example.csv\", header=True)\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a854fc0c-5340-4d78-8a51-9e09e7f5586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReadFromHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Đọc file CSV từ HDFS với tiêu đề\n",
    "df = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/example.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Hiển thị dữ liệu\n",
    "df.show()\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a08b8e-29b8-4034-9f82-2aa92341fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AddDataToHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Tạo một DataFrame mẫu mới\n",
    "new_data = [(\"Alice\", \"Brown\", \"Canada\", \"ON\"),\n",
    "            (\"John\", \"Doe\", \"UK\", \"London\"),\n",
    "            (\"Emma\", \"Watson\", \"France\", \"Paris\")]\n",
    "\n",
    "new_columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "\n",
    "new_df = spark.createDataFrame(new_data, schema=new_columns)\n",
    "\n",
    "# Ghi DataFrame mới vào HDFS vào thư mục khác\n",
    "new_df.write.csv(\"hdfs://namenode:9000/user/nhatrinh/new_data.csv\", header=True)\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "763f0957-4c14-461f-83a8-dc1d0c539039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/06 02:19:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+------+\n",
      "|firstname|lastname|country| state|\n",
      "+---------+--------+-------+------+\n",
      "|   Robert|Williams|    USA|    CA|\n",
      "|  Michael|    Rose|    USA|    NY|\n",
      "|    James|   Smith|    USA|    CA|\n",
      "|    Maria|   Jones|    USA|    FL|\n",
      "|     Emma|  Watson| France| Paris|\n",
      "|    Alice|   Brown| Canada|    ON|\n",
      "|     John|     Doe|     UK|London|\n",
      "+---------+--------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReadAllDataFromHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Đọc dữ liệu từ file cũ\n",
    "df_old = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/example.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Đọc dữ liệu từ file mới\n",
    "df_new = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/new_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Kết hợp dữ liệu (union)\n",
    "df_all = df_old.union(df_new)\n",
    "\n",
    "# Hiển thị dữ liệu kết hợp\n",
    "df_all.show()\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
