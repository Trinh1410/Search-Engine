{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee1f5a2-202c-4e50-811c-bd9fa564cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession và thiết lập mức log\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AddStudentDataToHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Thiết lập mức log để giảm thiểu cảnh báo\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Tạo một DataFrame mẫu mới về sinh viên\n",
    "student_data = [(\"John\", \"Doe\", \"123456\", \"Computer Science\"),\n",
    "                (\"Jane\", \"Smith\", \"654321\", \"Mathematics\"),\n",
    "                (\"Emily\", \"Jones\", \"789012\", \"Physics\")]\n",
    "\n",
    "student_columns = [\"firstname\", \"lastname\", \"student_id\", \"major\"]\n",
    "\n",
    "student_df = spark.createDataFrame(student_data, schema=student_columns)\n",
    "\n",
    "# Ghi DataFrame mới vào HDFS vào thư mục khác\n",
    "student_df.write.csv(\"hdfs://namenode:9000/user/nhatrinh/student_data.csv\", header=True)\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f89181-be81-42d4-8455-c8b5f07992cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+----------------+\n",
      "|firstname|lastname|country|           state|\n",
      "+---------+--------+-------+----------------+\n",
      "|   Robert|Williams|    USA|              CA|\n",
      "|  Michael|    Rose|    USA|              NY|\n",
      "|    James|   Smith|    USA|              CA|\n",
      "|    Maria|   Jones|    USA|              FL|\n",
      "|     Emma|  Watson| France|           Paris|\n",
      "|    Alice|   Brown| Canada|              ON|\n",
      "|     John|     Doe|     UK|          London|\n",
      "|     John|     Doe| 123456|Computer Science|\n",
      "|     Jane|   Smith| 654321|     Mathematics|\n",
      "|    Emily|   Jones| 789012|         Physics|\n",
      "+---------+--------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi động SparkSession và thiết lập mức log\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReadAllDataFromHDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Thiết lập mức log để giảm thiểu cảnh báo\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Đọc dữ liệu từ file cũ\n",
    "df_old = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/example.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Đọc dữ liệu từ file mới\n",
    "df_new = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/new_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Đọc dữ liệu từ file sinh viên\n",
    "df_student = spark.read.csv(\"hdfs://namenode:9000/user/nhatrinh/student_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Hiển thị dữ liệu kết hợp (nếu cần thiết, có thể kết hợp dữ liệu thành một DataFrame duy nhất)\n",
    "df_all = df_old.union(df_new).union(df_student)\n",
    "\n",
    "# Hiển thị dữ liệu kết hợp\n",
    "df_all.show()\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
